{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo==4.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient \n",
    "from pymongo.errors import PyMongoError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "mydatabase = client['ubuntu4'] \n",
    "mycollection = mydatabase['users']\n",
    "record = {\n",
    "'title': 'MongoDB and Python', \n",
    "'description': 'MongoDB is no SQL database', \n",
    "'tags': ['mongodb', 'database', 'NoSQL'], \n",
    "'viewers': 104 \n",
    "}\n",
    "rec = mydatabase.myTable.insert_one(record) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpdateResult({'n': 0, 'nModified': 0, 'ok': 1.0, 'updatedExisting': False}, acknowledged=True)\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.test\n",
    "coll = db.test\n",
    "\n",
    "def update_device(device_num, readingGram, lastRead):\n",
    "    return coll.update_one({'device': device_num}, {'$set': {'readingGram': readingGram, 'lastRead': lastRead}})\n",
    "\n",
    "print(update_device(0, 100, 123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "input_files = [\"users\", \"badges\", \"tags\", \"posts\", \"posttags\", \"comments\", \"dummy\"]\n",
    "\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'port': 27017,\n",
    "    'database': 'ubuntu4'\n",
    "}\n",
    "\n",
    "data_directory = 'C:\\\\Users\\\\Muhammad Raees\\\\OneDrive - rit.edu\\\\Python_Projects\\\\BigData\\\\small_data\\\\'\n",
    "\n",
    "chunk_size = 5\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to connect with database\n",
    "def connect():\n",
    "    try:\n",
    "        client = MongoClient(host=db_config['host'], \n",
    "                         port=db_config['port'])\n",
    "        return client[db_config['database']]  # Return the database object\n",
    "    except PyMongoError as e:\n",
    "        print(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_existing_ids(collection, key):\n",
    "    # collection = 'users', key = 'Id'\n",
    "    db = connect()\n",
    "    existing_data = db[collection].find({}, {'_id': 1, key: 1})\n",
    "    return {str(doc[key]): doc['_id'] for doc in existing_data}\n",
    "\n",
    "def extract_ids(chunk_data, key):\n",
    "    # key = 'Id'\n",
    "    return {entry[key] for entry in chunk_data if key in entry}\n",
    "\n",
    "def filter_and_replace_ids(chunk_data, existing_ids, key):\n",
    "    valid_chunk_data = []\n",
    "\n",
    "    for entry in chunk_data:\n",
    "        test_id = str(entry.get(key))\n",
    "        # print('test_id:', test_id)  # Debug print to check the value of test_id\n",
    "\n",
    "        # Ensure test_id is a string for comparison\n",
    "        if test_id is not None and str(test_id) in existing_ids:\n",
    "            # print('test_id in existing_ids:', test_id)  # Debug print to confirm matching ID\n",
    "            # Replace UserId with corresponding _id\n",
    "            entry[key] = existing_ids[str(test_id)]  # Convert test_id to string for dictionary lookup\n",
    "            valid_chunk_data.append(entry)\n",
    "\n",
    "    return valid_chunk_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-1': ObjectId('67148c60456d2db8d608ad98'), '2': ObjectId('67148c60456d2db8d608ad99'), '3': ObjectId('67148c60456d2db8d608ad9a'), '4': ObjectId('67148c60456d2db8d608ad9b'), '5': ObjectId('67148c60456d2db8d608ad9c')}\n",
      "Processed 1 chunks for about 5 elements.\n"
     ]
    }
   ],
   "source": [
    "def insert_posts(input_file, max_chunks=5):\n",
    "    db = connect()\n",
    "    collection = db['posts']\n",
    "    input_file = data_directory + input_file\n",
    "    context = ET.iterparse(input_file, events=(\"start\", \"end\"))\n",
    "    \n",
    "    chunk_count = 0\n",
    "    elements_in_chunk = 0\n",
    "    chunk_data = []\n",
    "\n",
    "    for event, elem in context:\n",
    "        if elem.tag == 'row':\n",
    "            if elem.get('Id') is not None and elem.get('OwnerUserId') is not None: \n",
    "                # get posts data to insert into posts\n",
    "                tags_string = elem.get('Tags')\n",
    "                tag_list = []\n",
    "                if tags_string:\n",
    "                    tags = [tag.strip('>') for tag in tags_string.split('<') if tag.strip()]\n",
    "                    tag_list = [tag for tag in tags if tag]\n",
    "                document = {\n",
    "                \"Id\": elem.get('Id'),\n",
    "                \"ParentId\": elem.get('ParentId'),\n",
    "                \"OwnerUserId\": elem.get('OwnerUserId'),\n",
    "                \"AcceptedAnswerId\": elem.get('AcceptedAnswerId'),\n",
    "                \"Title\": elem.get('Title'),\n",
    "                \"Body\": elem.get('Body'),\n",
    "                \"Score\": elem.get('Score'),\n",
    "                \"ViewCount\": elem.get('ViewCount'),\n",
    "                \"CreationDate\": elem.get('CreationDate'),\n",
    "                \"Tags\": tag_list,\n",
    "                'Comments': []\n",
    "                }\n",
    "                \n",
    "                chunk_data.append(document)\n",
    "                elements_in_chunk += 1\n",
    "\n",
    "            # If chunk is full, save the chunk and reset\n",
    "            if elements_in_chunk >= chunk_size:\n",
    "                chunk_count += 1\n",
    "                # Insert into db\n",
    "                existing_ids = fetch_existing_ids('users', 'Id')\n",
    "                print(existing_ids)\n",
    "                valid_chunk_data = filter_and_replace_ids(chunk_data, existing_ids, 'OwnerUserId')\n",
    "\n",
    "                # Insert valid data into the collection\n",
    "                if valid_chunk_data:\n",
    "                    collection.insert_many(valid_chunk_data)\n",
    "                chunk_data = []  \n",
    "                elements_in_chunk = 0\n",
    "\n",
    "            # Clear the element to free up memory\n",
    "            elem.clear()\n",
    "    \n",
    "    # Processing the remaining data in final chunk\n",
    "    if elements_in_chunk > 0:\n",
    "        chunk_count += 1\n",
    "        # Insert into db\n",
    "        existing_ids = fetch_existing_ids('users', 'Id')\n",
    "        print(existing_ids)\n",
    "\n",
    "        valid_chunk_data = filter_and_replace_ids(chunk_data, existing_ids, 'OwnerUserId')\n",
    "\n",
    "        # Insert valid data into the collection\n",
    "        if valid_chunk_data:\n",
    "            collection.insert_many(valid_chunk_data)\n",
    "        chunk_data = []  \n",
    "        elements_in_chunk = 0\n",
    "\n",
    "    print(f\"Processed {chunk_count} chunks for about {chunk_size} elements.\")\n",
    "\n",
    "insert_posts(\"Posts.xml\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No update needed for post 60036.\n",
      "No update needed for post 60036.\n",
      "No update needed for post 60037.\n",
      "No update needed for post 56973.\n",
      "No update needed for post 56973.\n",
      "No update needed for post 56974.\n"
     ]
    }
   ],
   "source": [
    "def update_posts_with_comments(chunk_data):\n",
    "    db = connect()\n",
    "    collection = db['posts']\n",
    "    \n",
    "    for post_id, comment in chunk_data:\n",
    "        try:\n",
    "            # Update using the UserId field instead of _id\n",
    "            result = collection.update_one(\n",
    "                {'Id': post_id},  # Use UserId for filtering\n",
    "                {'$addToSet': {'Comments': comment}},\n",
    "                upsert=False  # Don't insert if user doesn't exist\n",
    "            )\n",
    "            if result.modified_count > 0:\n",
    "                print(f\"Updated post {post_id} with cemment {comment['Text']}.\")\n",
    "            else:\n",
    "                print(f\"No update needed for post {post_id}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating user {post_id}: {e}\")\n",
    "\n",
    "def insert_comments(input_file, max_chunks=10):\n",
    "    input_file = data_directory + input_file\n",
    "    context = ET.iterparse(input_file, events=(\"start\", \"end\"))\n",
    "    \n",
    "    chunk_count = 0\n",
    "    elements_in_chunk = 0\n",
    "    chunk_data = []  \n",
    "    \n",
    "    for event, elem in context:\n",
    "        if elem.tag == 'row':\n",
    "            if elem.get('Id') is not None and elem.get('PostId') is not None and elem.get('UserId') is not None:\n",
    "                comment_data = {\n",
    "                    \"Id\": elem.get('Id'),\n",
    "                    \"PostId\": elem.get('PostId'),\n",
    "                    \"Score\": elem.get('Score'),\n",
    "                    \"Text\": elem.get('Text'),\n",
    "                    \"CreationDate\": elem.get('CreationDate'),\n",
    "                    \"UserId\": elem.get('UserId')\n",
    "                }\n",
    "                post_id = elem.get('PostId')\n",
    "                chunk_data.append((post_id, comment_data))\n",
    "                elements_in_chunk += 1\n",
    "\n",
    "            if elements_in_chunk >= chunk_size:\n",
    "                chunk_count += 1\n",
    "                update_posts_with_comments(chunk_data)\n",
    "                chunk_data = [] \n",
    "                elements_in_chunk = 0\n",
    "            elem.clear()\n",
    "\n",
    "    # Process any remaining data\n",
    "    if elements_in_chunk > 0: \n",
    "        chunk_count += 1\n",
    "        update_posts_with_comments(chunk_data)\n",
    "\n",
    "insert_comments(\"Comments.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: users   Documents: 5\n",
      "Collection: posts   Documents: 8\n"
     ]
    }
   ],
   "source": [
    "def report_db_statistics():\n",
    "    db = connect()\n",
    "    collections = db.list_collection_names()\n",
    "    for collection_name in collections:\n",
    "        count = db[collection_name].count_documents({})\n",
    "        print(f\"Collection: {collection_name}   Documents: {count}\")\n",
    "report_db_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67157b59d559a31da2124c79'), 'Id': '-1', 'AccountId': '-1', 'DisplayName': 'Community', 'AboutMe': '<p>Hi, I\\'m not really a person.</p>\\n<p>I\\'m a background process that helps keep this site clean!</p>\\n<p>I do things like</p>\\n<ul>\\n<li>Randomly poke old unanswered questions every hour so they get some attention</li>\\n<li>Own community questions and answers so nobody gets unnecessary reputation from them</li>\\n<li>Own downvotes on spam/evil posts that get permanently deleted</li>\\n<li>Own suggested edits from anonymous users</li>\\n<li><a href=\"https://meta.stackexchange.com/a/92006\">Remove abandoned questions</a></li>\\n</ul>\\n', 'CreationDate': '2010-07-28T16:38:27.683', 'Reputation': '1', 'Badges': []}\n",
      "{'_id': ObjectId('67157b59d559a31da2124c7a'), 'Id': '2', 'AccountId': '2', 'DisplayName': 'Geoff Dalgas', 'AboutMe': '<p>Dev #2 who helped create Stack Overflow currently working at Microsoft. I love all people willing to share their knowledge. Without community we are nothing.</p>\\n<p>Find me on:</p>\\n<p><a href=\"http://www.twitter.com/SuperDalgas\" rel=\"nofollow noreferrer\">Twitter</a>\\n<br><br>\\n<a href=\"http://blog.stackoverflow.com/2009/05/welcome-stack-overflow-valued-associate-00003/\">Stack Overflow Valued Associate #00003</a></p>\\n', 'CreationDate': '2010-07-28T17:09:21.300', 'Reputation': '101', 'Badges': [{'Id': '4', 'UserId': ObjectId('67157b59d559a31da2124c7a'), 'Name': 'Autobiographer', 'Date': '2010-07-28T19:09:00.633'}]}\n",
      "{'_id': ObjectId('67157b59d559a31da2124c7b'), 'Id': '3', 'AccountId': '3', 'DisplayName': 'Jarrod Dixon', 'AboutMe': '<p>Former <a href=\"http://blog.stackoverflow.com/2009/01/welcome-stack-overflow-valued-associate-00002/\">Developer on the Stack Overflow team</a>.</p>\\n<p>Was dubbed <strong>SALTY SAILOR</strong> by Jeff Atwood, as filth and flarn would oft-times fly when dealing with a particularly nasty bug!</p>\\n<ul>\\n<li>Twitter me: <a href=\"http://twitter.com/jarrod_dixon\" rel=\"nofollow noreferrer\">jarrod_dixon</a></li>\\n<li>Email me: jarrod.m.dixon@gmail.com</li>\\n</ul>\\n', 'CreationDate': '2010-07-28T18:00:10.977', 'Reputation': '101', 'Badges': [{'Id': '2', 'UserId': ObjectId('67157b59d559a31da2124c7b'), 'Name': 'Supporter', 'Date': '2010-07-28T19:09:00.510'}, {'Id': '5', 'UserId': ObjectId('67157b59d559a31da2124c7b'), 'Name': 'Autobiographer', 'Date': '2010-07-28T19:09:00.633'}]}\n",
      "{'_id': ObjectId('67157b59d559a31da2124c7c'), 'Id': '4', 'AccountId': '45805', 'DisplayName': 'txwikinger', 'AboutMe': '<p>Ubuntu member, Kubuntu member</p>\\n', 'CreationDate': '2010-07-28T18:52:56.703', 'Reputation': '28114', 'Badges': [{'Id': '3', 'UserId': ObjectId('67157b59d559a31da2124c7c'), 'Name': 'Supporter', 'Date': '2010-07-28T19:09:00.527'}, {'Id': '6', 'UserId': ObjectId('67157b59d559a31da2124c7c'), 'Name': 'Autobiographer', 'Date': '2010-07-28T19:09:00.667'}]}\n",
      "{'_id': ObjectId('67157b59d559a31da2124c7d'), 'Id': '5', 'AccountId': '65895', 'DisplayName': 'Nathan Osman', 'AboutMe': '<p><strong>Email:</strong> <em>nathan@quickmediasolutions.com</em></p>\\n\\n<p>I am both an Ubuntu user and Ubuntu member. By profession, I am a software developer and I work with C++, Python, and (more recently) Go. I enjoy tinkering with different things like <a href=\"https://www.youtube.com/watch?v=eI75kNvD-Co\" rel=\"nofollow noreferrer\">motion tracking in Blender</a>, <a href=\"https://play.google.com/store/apps/details?id=com.nathanosman.chronosnap\" rel=\"nofollow noreferrer\">creating an Android app for time-lapse photography</a>, or <a href=\"https://github.com/nathan-osman/Webmail-Notifier-Linux-Driver\" rel=\"nofollow noreferrer\">writing Linux kernel modules</a>.</p>\\n\\n<p><sub>\\n - <a href=\"http://2buntu.com\" rel=\"nofollow noreferrer\">2buntu</a> - community blog that I sometimes contribute to<br>\\n - <a href=\"http://nitroshare.net\" rel=\"nofollow noreferrer\">NitroShare</a> - a cross-platform network file transfer utility<br>\\n - <a href=\"https://addons.mozilla.org/en-us/firefox/addon/rest-easy/\" rel=\"nofollow noreferrer\">REST Easy</a> - Firefox add-on for analyzing HTTP responses\\n</sub></p>\\n', 'CreationDate': '2010-07-28T19:02:12.130', 'Reputation': '32045', 'Badges': [{'Id': '1', 'UserId': ObjectId('67157b59d559a31da2124c7d'), 'Name': 'Student', 'Date': '2010-07-28T19:09:00.243'}]}\n",
      "{'_id': ObjectId('67157b59d559a31da2124c7e'), 'Id': '6', 'AccountId': '1998', 'DisplayName': 'Emmett', 'AboutMe': '<p>co-founder of <a href=\"https://airtable.com\" rel=\"nofollow noreferrer\">Airtable</a></p>\\n\\n<p>formerly a dev at Stack Overflow :)</p>\\n', 'CreationDate': '2010-07-28T19:04:10.020', 'Reputation': '101', 'Badges': []}\n"
     ]
    }
   ],
   "source": [
    "# def cleaning_database():\n",
    "#     db = connect()\n",
    "#     collections = db.list_collection_names()\n",
    "#     for collection_name in collections:\n",
    "#         db[collection_name].drop()\n",
    "#         print(f\"Deleted collection: {collection_name}\")\n",
    "# cleaning_database()\n",
    "db = connect()\n",
    "docs = db.users.find()\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postgre', 'database']\n"
     ]
    }
   ],
   "source": [
    "input_string = \"<postgre><database>\"\n",
    "\n",
    "# Remove the angle brackets and split the string based on the brackets\n",
    "words = input_string.replace('<', ' ').replace('>', ' ').split()\n",
    "\n",
    "# Filter out any empty strings\n",
    "word_list = [word for word in words if word]\n",
    "\n",
    "print(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... 100%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    " # Import the time module, which provides time-related functions like sleep()\n",
    "import time\n",
    "# Loop over a range of numbers from 1 to 5 (inclusive)\n",
    "for i in range(1, 6):\n",
    "    # Print a loading message with a percentage that updates on the same line\n",
    "    print(f\"\\rLoading... {i*20}%\", end=\"\")\n",
    "    # Pause the execution for 1 second to simulate a loading delay\n",
    "    time.sleep(1)\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
